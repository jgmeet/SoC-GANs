{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec363d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fba524c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569 30\n",
      "torch.Size([455, 30])\n",
      "torch.Size([455, 1])\n"
     ]
    }
   ],
   "source": [
    "# step 0 -> prepare data\n",
    "bc = datasets.load_breast_cancer() # for binary classification\n",
    "x,y = bc.data, bc.target\n",
    "n_samples, n_features = x.shape\n",
    "print(n_samples, n_features)\n",
    "x_train,x_test, y_train,y_test = train_test_split(x,y,test_size = 0.2)\n",
    "\n",
    "# scale\n",
    "# The transform method uses the parameters learned from the training data\n",
    "# (mean and standard deviation) and applies the same transformation to the test data (x_test).\n",
    "# It ensures that the test data is scaled in the same way as the training data, based on the previously learned parameters.\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)\n",
    "\n",
    "# tranform data to tensors\n",
    "x_train = torch.from_numpy(x_train.astype(np.float32))\n",
    "x_test = torch.from_numpy(x_test.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
    "\n",
    "# reshape y_train and y_test\n",
    "y_train = y_train.view(-1, 1)\n",
    "y_test = y_test.view(-1, 1)\n",
    "print(x_train.size())\n",
    "print(y_train.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "378d4d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "class logisticRegression(nn.Module):\n",
    "    def __init__(self, num_input_features):\n",
    "        super(logisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(num_input_features,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        y_hat = torch.sigmoid(self.linear(x))\n",
    "        return y_hat\n",
    "    \n",
    "\n",
    "model = logisticRegression(n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5cca9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimisers\n",
    "criterion = nn.BCELoss()\n",
    "learning_rate = 0.1\n",
    "optimiser = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f394266f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.7319\n",
      "epoch: 10, loss: 0.2578\n",
      "epoch: 20, loss: 0.1951\n",
      "epoch: 30, loss: 0.1667\n",
      "epoch: 40, loss: 0.1498\n",
      "epoch: 50, loss: 0.1383\n",
      "epoch: 60, loss: 0.1298\n",
      "epoch: 70, loss: 0.1232\n",
      "epoch: 80, loss: 0.1179\n",
      "epoch: 90, loss: 0.1136\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "n_epochs = 100\n",
    "for epoch in range(n_epochs):\n",
    "    # forward pass\n",
    "    y_hat = model(x_train)\n",
    "    \n",
    "    # calc loss\n",
    "    loss = criterion(y_hat, y_train)\n",
    "    \n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # update weights\n",
    "    optimiser.step()\n",
    "    \n",
    "    # reload gradients to zero\n",
    "    optimiser.zero_grad()\n",
    "    \n",
    "    if epoch % 10==0:\n",
    "        print(f'epoch: {epoch}, loss: {loss.item():.4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fba449f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9912\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_hat_test = model(x_test)\n",
    "    y_test_cls = y_hat_test.round()\n",
    "    acc = y_test_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
    "    print(f'accuracy: {acc.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a13e3e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "pt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
